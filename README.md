# Udacity_DeepLearning_ND
This Repository Contains my work going through the Deep Learning NanoDegree and any related materials that I completed in route to completing the NanoDegree.  There are 5 main projects in the program and many smaller mini projects, with some of that work being represented in this repository.  

## **Main Projects in the NanoDegree are:** 
  1. [My first Neural Network](#project-1-my-first-neural-network)
  2. [Dog Project](#project-2-dog-project)
  3. [Script Generation](#project-3-script-generation)
  4. [Face Generation (Not Yet Compeleted)](#project-4-face-generation) 
  5. [Teach a Quadcopter to fly (Not yet Completed)](#project-5-teach-a-quadcopter-to-fly)
  

## **Project 1: My First Neural Network**  
### **_Description:_** 
 The goal of this project is to build a multi-layer perceptron neural network in 
 order to predict bike sharing rates.  The network will predict the amount of 
 bikes that are needed based on previous historical business data. 

### **_Technical Concepts Used:_**
  - Data Processing and Loading  
  - Multi-Layer Perceptron
  - Training and Validation Loss
  - Forward Propagation 
  - Backward Propagation 
  - Numpy 
  
### **_What I learned:_**
I learned to implement a simple multi-layer perceptron neural network from 
scratch using numpy.  I was able to implement concepts that are crucial to
neural networks such as forward propagation, backpropagation, and cross entropy loss. 
I also learned how to look at training and validation loss graphs to determine how to adjust 
model parameters to improve the performance of the model.  

[see code here](/First-Neural-Network)


## **Project 2: Dog Project** 

### **_Description:_**
This project focused on building a pipeline to process real world images.
The pipeline contained a Convolutional Neural Network that will allow the 
user to supply an image and the network will determine two things:         
1. Is there a dog in the image
2. If there is a dog, what breed of dog is in the image


### **_Technical Concepts Used:_**
   - Convolutional Neural Networks (CNN)
   - Keras 
   - Max pooling layers 
   - Drop out layers 
   - Convolutional Layers
   - Fully Connected Layers
   - Cv2
   - Object Detection 
   - Image Processing 
   - Model Checkpoints 
   - Using Pre-trained models 
  
### **_What I learned:_**
I learned many of the concepts related to CNNs and how to implement them
in a real world scenario.  During the implementation of the pipeline, I learned to 
build CNNs in Keras and using the different type of layers to use create different 
types of architectures.  This project allowed me to explore using pretrained models and adding layers 
to the end of it to improve the performance without having to go through long training times. 

[see code here](/dog-project)

## **Project 3: Script Generation**
### **_Description:_**
In this project, an RNN was built to generate a Simpson's TV script using a
portion of the scripts from the 27 seasons. The new script will be a newly generated 
scene based on the data the model was trained on.  The model was only trained on a portion of the 
data set to reduce the training time.  It produced a script in Moe's Tavern. 

### **_Technical Concepts Used:_**
  - Recurrent Neural Network (RNN)
  - Textual preprocessing 
  - Tokenization
  - TensorFlow 
  - LSTM Cells
  - Word Embeddings 
  - Build RNN from Scratch 
  - Batching 
  - Tuning Hyperparameters 
  - Building TensorFlow Graphs 
  
### **_What I learned:_**
  I learned how to implement an RNN from scratch using TensorFlow.  Previously. 
  I had been using the Keras library to build the models at a higher level and this project 
  really made me learn the low level concepts that are involved in building these models.  Also, 
  I learned to implement the concepts behind recurrent neural networks and what makes them successful in 
  tasks like natural language processing.
  
  [see code here](/tv-script-generation)
  

## **Project 4: Face Generation** 
### **_Description:_**
In this project, I made a a GAN neural network to generate fake images of celebrity faces.  The neural network is composed of two neural networks, a generator and a discriminator.  The generator starts with random noise vector and learns to generate images and the discriminator works to identify fake images that are generated by the generator network.  The two networks are competing with one another that allows the GAN network to work. 

### **_Technical Concepts Used:_**
- GANs 
- DCGAN Architecture 
- Image Generation 
- Generator Creation 
- Discriminator Creation 
- Tensorflow 1.0
- Loss function implementation
- Optimizer implementation
  
### **_What I learned:_**
I learned how to implement a Generative Adversarial Network from scratch using tensorflow.  I also learned some of the theoretical concepts that are applied to building these networks.  I also worked with the various parameters within this type of network and how to optimize them to maximize the performance of the model.  Through my research into how to improve the perfromance of my model, I discovered techniques to help the GAN converge and improve the functionality of the model.  
  

## **Project 5: Teach a Quadcopter to fly**
  ### **_Description:_**
  TBD


  ### **_Technical Concepts Used:_**
  TBD
  
  
  
  ### **_What I learned:_**
  TBD
  
  
  
  
  
  _*Please feel free to reference the code in this repository but please attempt 
  to understand everything that underlies the code in the notebooks. 
  Try not to simply copy and paste code!_
